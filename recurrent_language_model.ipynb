{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNmL4B9I_40H"
      },
      "source": [
        "##Download data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFljmmGYB2pb",
        "outputId": "dd221f0c-e71b-4a7b-e98c-d144ba86e252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-11 00:54:06--  https://www.gutenberg.org/cache/epub/1497/pg1497.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243940 (1.2M) [text/plain]\n",
            "Saving to: ‘pg1497.txt’\n",
            "\n",
            "pg1497.txt          100%[===================>]   1.19M   875KB/s    in 1.4s    \n",
            "\n",
            "2022-12-11 00:54:09 (875 KB/s) - ‘pg1497.txt’ saved [1243940/1243940]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.gutenberg.org/cache/epub/1497/pg1497.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZy15UYxHtOk"
      },
      "source": [
        "##Data Loading \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6iHD66o6Hz5E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P5sA7GoXDD49"
      },
      "outputs": [],
      "source": [
        "file = open('pg1497.txt', 'r')\n",
        "document = file.read()\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeP1MtY7Ctxl",
        "outputId": "f6948a26-39cc-4bba-97ed-3b318aed477c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Republic, by Plato\n",
            "\n",
            "This eBook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this eBook or online at\n",
            "www.gutenberg.org. If you are not located in the United States, you\n",
            "will have to check the laws of the country where you are located before\n",
            "using this eBook.\n",
            "\n",
            "Title: The Republic\n",
            "\n",
            "Author: Plato\n",
            "\n",
            "Translator: B. Jowett\n",
            "\n",
            "Release Date: October, 1998 [eBook #1497]\n",
            "[Most recently updated: September 11, 2021]\n",
            "\n",
            "Language: English\n",
            "\n",
            "\n",
            "Produced by: Sue Asscher and David Widger\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK THE REPUBLIC ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "THE REPUBLIC\n",
            "\n",
            "By Plato\n",
            "\n",
            "Translated by Benjamin Jowett\n",
            "\n",
            "Note: See also “The Republic” by Plato, Jowett, eBook #150\n",
            "\n",
            "\n",
            "Contents\n",
            "\n",
            " INTRODUCTION AND ANALYSIS.\n",
            " THE REPUBLIC.\n",
            " PERSONS OF THE DIALOGUE.\n",
            " BOOK I.\n",
            " BOOK II.\n",
            " BOOK III.\n",
            " BOO\n"
          ]
        }
      ],
      "source": [
        "print(document[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6nvVuA6JNei"
      },
      "source": [
        "##search and extract specific word from document "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WcoUgNsqG_xS"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm4EWwv3G9sM",
        "outputId": "15ff6078-63bd-4375-c4e1-6797661a4a5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[967, 38188, 553671]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "[m.start() for m in re.finditer(\"BOOK I\\.\", document)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvf2Fin2Id7i",
        "outputId": "ad44b946-682b-4c26-e593-a6f9813427dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOOK I.\n",
            " BOOK II.\n",
            " BOOK III.\n",
            " BOOK IV.\n",
            " BOOK V.\n",
            " BOOK VI.\n",
            " BOOK VII.\n",
            " BOOK VIII.\n",
            " BOOK IX.\n",
            " BOOK X.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " INTRODUCTION AND ANALYSIS.\n",
            "\n",
            "\n",
            "The Republic of Plato is the longest of his works with the exception of\n",
            "the Laws, and is certainly the greatest of them. There are nearer\n",
            "approaches to modern metaphy\n"
          ]
        }
      ],
      "source": [
        "book_ft = document[967:553678]\n",
        "print(book_ft[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJKBSshRICFz",
        "outputId": "9cc1aca1-2d2d-4adf-9de5-f9be332968c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOOK I. The Republic opens with a truly Greek scene—a festival in\n",
            "honour of the goddess Bendis which is held in the Piraeus; to this is\n",
            "added the promise of an equestrian torch-race in the evening. The whole\n",
            "work is supposed to be recited by Socrates on the day after the\n",
            "festival to a small party, c\n"
          ]
        }
      ],
      "source": [
        "book_st = document[38188:553671]\n",
        "print(book_st[:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpLsSHFLHLgK",
        "outputId": "9a7b1f26-7376-4e34-e336-526b99c67013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOOK I.\n",
            "\n",
            "\n",
            "I went down yesterday to the Piraeus with Glaucon the son of Ariston,\n",
            "that I might offer up my prayers to the goddess (Bendis, the Thracian\n",
            "Artemis.); and also because I wanted to see in what manner they would\n",
            "celebrate the festival, which was a new thing. I was delighted with the\n",
            "processi\n"
          ]
        }
      ],
      "source": [
        "book_tt = document[553671:1195644]\n",
        "print(book_tt[:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XYC6vyM97UE"
      },
      "source": [
        "##Text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nzA4tJURCZNS"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "#remove the punctuation\n",
        "document_cleaned=document.translate(str.maketrans('', '', string.punctuation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1COCrQ8oC-b0"
      },
      "outputs": [],
      "source": [
        "document_tokens = document_cleaned.split()\n",
        "document_tokens = [word for word in document_tokens if word.isalpha()]\n",
        "document_tokens = [word.lower() for word in document_tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YAnm-xSDdRX",
        "outputId": "9b1e2bf7-2a83-424e-afb4-68418ee50ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['project', 'gutenberg', 'ebook', 'of', 'the', 'republic', 'by', 'plato', 'this', 'ebook']\n"
          ]
        }
      ],
      "source": [
        "# print list of tokens\n",
        "print(document_tokens[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRIwMjJCDSTS",
        "outputId": "d1749b49-da17-4a15-f9d0-7139009f586b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of Tokens >>>>> 216371\n",
            "Total number of Unique Tokens >>>>>  10489\n"
          ]
        }
      ],
      "source": [
        "print('Total number of Tokens >>>>>',len(document_tokens))\n",
        "print('Total number of Unique Tokens >>>>> ',len(set(document_tokens)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SIq4YvrH9A8",
        "outputId": "de2b239d-61e9-47be-97c3-fae36d95e5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of Sequences >>>>> 4243\n"
          ]
        }
      ],
      "source": [
        "length_of_seq = 50+1\n",
        "sequences = list()\n",
        "for i in range(0,len(document_tokens),length_of_seq):\n",
        "    seq = document_tokens[i:length_of_seq+i] \n",
        "    line = ' '.join(seq)\n",
        "    sequences.append(line)\n",
        "print('Total number of Sequences >>>>>',len(sequences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtoatlKpSQP_"
      },
      "source": [
        "##Encode the training data (encode sequences)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c7eshI3FSALS"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "encoded = tokenizer.texts_to_sequences(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVZnqyMofiuz",
        "outputId": "da0859c5-004c-4fa6-d514-ad9dff589f38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4243"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msCdaEG5TdWb",
        "outputId": "92cebbba-af3f-4bc5-cc5f-a45072d66385"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "type(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "od_GAYdWTnZp"
      },
      "outputs": [],
      "source": [
        "encoded = np.array(encoded[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV0rYgvjSe_Q",
        "outputId": "24f9bb85-c9c3-481e-d4bf-87466ee4b8cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10490"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fhPWssjpTSlS"
      },
      "outputs": [],
      "source": [
        "# separate sequences into input and output\n",
        "X = encoded[:,:-1]\n",
        "y = encoded[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IPQzQ6i1StvV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCT_Ph0wTksr",
        "outputId": "c7da234c-cdf8-4adf-ca4a-089e5a2311c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKJHVCJQURya",
        "outputId": "14f2d847-6900-4e56-d3ac-c4c3c726617f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4242, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY47WfGEUSZh",
        "outputId": "e8e35133-a61b-4747-bedc-68fa49acd460"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4242, 10490)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdMx1lAfUvuJ"
      },
      "source": [
        "##Trial_1 using SimpleRNN,Embedding, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TX2LwPK4Y7zv"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "J37oTjgnYQ7r"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model_T1 = Sequential()\n",
        "model_T1.add(Embedding(vocab_size,50,input_length=seq_length))\n",
        "model_T1.add(SimpleRNN(200, return_sequences=True))\n",
        "model_T1.add(SimpleRNN(200))\n",
        "model_T1.add(Dropout(0.2))\n",
        "model_T1.add(Dense(vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4wtfj_cZYRB",
        "outputId": "4026a660-0ca2-4a4b-f09c-b0496afeaf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 50)            524500    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 50, 200)           50200     \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 200)               80200     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10490)             2108490   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,763,390\n",
            "Trainable params: 2,763,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_T1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "x3WuPiYDY-dy"
      },
      "outputs": [],
      "source": [
        "model_T1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPo0dHaQZSTM",
        "outputId": "4b372d55-b0c8-4ddf-84c6-c4cd958f0554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "34/34 [==============================] - 7s 94ms/step - loss: 7.5811 - accuracy: 0.0674\n",
            "Epoch 2/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 6.1344 - accuracy: 0.0761\n",
            "Epoch 3/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 5.9840 - accuracy: 0.0757\n",
            "Epoch 4/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 5.9414 - accuracy: 0.0731\n",
            "Epoch 5/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 5.9287 - accuracy: 0.0728\n",
            "Epoch 6/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 5.9186 - accuracy: 0.0721\n",
            "Epoch 7/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 5.9154 - accuracy: 0.0705\n",
            "Epoch 8/300\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 5.9054 - accuracy: 0.0759\n",
            "Epoch 9/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 5.9099 - accuracy: 0.0754\n",
            "Epoch 10/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 5.9098 - accuracy: 0.0740\n",
            "Epoch 11/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 5.9131 - accuracy: 0.0764\n",
            "Epoch 12/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 5.9134 - accuracy: 0.0717\n",
            "Epoch 13/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 5.9104 - accuracy: 0.0764\n",
            "Epoch 14/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 5.9064 - accuracy: 0.0750\n",
            "Epoch 15/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 5.9168 - accuracy: 0.0747\n",
            "Epoch 16/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 5.9091 - accuracy: 0.0757\n",
            "Epoch 17/300\n",
            "34/34 [==============================] - 4s 106ms/step - loss: 5.9141 - accuracy: 0.0752\n",
            "Epoch 18/300\n",
            "34/34 [==============================] - 4s 122ms/step - loss: 5.9196 - accuracy: 0.0757\n",
            "Epoch 19/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 5.9142 - accuracy: 0.0750\n",
            "Epoch 20/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 5.9077 - accuracy: 0.0747\n",
            "Epoch 21/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 5.9140 - accuracy: 0.0757\n",
            "Epoch 22/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 5.9156 - accuracy: 0.0759\n",
            "Epoch 23/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 5.9160 - accuracy: 0.0736\n",
            "Epoch 24/300\n",
            "34/34 [==============================] - 4s 110ms/step - loss: 5.9108 - accuracy: 0.0757\n",
            "Epoch 25/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 5.9238 - accuracy: 0.0747\n",
            "Epoch 26/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 5.9336 - accuracy: 0.0721\n",
            "Epoch 27/300\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 5.9225 - accuracy: 0.0752\n",
            "Epoch 28/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 5.7404 - accuracy: 0.0745\n",
            "Epoch 29/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 6.8069 - accuracy: 0.0653\n",
            "Epoch 30/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 6.7759 - accuracy: 0.0646\n",
            "Epoch 31/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 6.3898 - accuracy: 0.0653\n",
            "Epoch 32/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 5.7613 - accuracy: 0.0740\n",
            "Epoch 33/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 6.5150 - accuracy: 0.0747\n",
            "Epoch 34/300\n",
            "34/34 [==============================] - 4s 104ms/step - loss: 6.8226 - accuracy: 0.0547\n",
            "Epoch 35/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 5.6142 - accuracy: 0.0785\n",
            "Epoch 36/300\n",
            "34/34 [==============================] - 4s 120ms/step - loss: 5.3946 - accuracy: 0.0816\n",
            "Epoch 37/300\n",
            "34/34 [==============================] - 4s 115ms/step - loss: 5.2473 - accuracy: 0.0941\n",
            "Epoch 38/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 5.1079 - accuracy: 0.1051\n",
            "Epoch 39/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 4.9892 - accuracy: 0.1117\n",
            "Epoch 40/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 4.8491 - accuracy: 0.1176\n",
            "Epoch 41/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 4.7226 - accuracy: 0.1271\n",
            "Epoch 42/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 4.5966 - accuracy: 0.1334\n",
            "Epoch 43/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 4.4768 - accuracy: 0.1452\n",
            "Epoch 44/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 4.3518 - accuracy: 0.1575\n",
            "Epoch 45/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 4.2242 - accuracy: 0.1726\n",
            "Epoch 46/300\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 4.1191 - accuracy: 0.1876\n",
            "Epoch 47/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 3.9992 - accuracy: 0.1980\n",
            "Epoch 48/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 3.8983 - accuracy: 0.2110\n",
            "Epoch 49/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 3.7863 - accuracy: 0.2242\n",
            "Epoch 50/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 3.7182 - accuracy: 0.2308\n",
            "Epoch 51/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 3.8299 - accuracy: 0.2251\n",
            "Epoch 52/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 4.0817 - accuracy: 0.2046\n",
            "Epoch 53/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 3.8300 - accuracy: 0.2282\n",
            "Epoch 54/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 3.6986 - accuracy: 0.2336\n",
            "Epoch 55/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 3.5231 - accuracy: 0.2647\n",
            "Epoch 56/300\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 3.3682 - accuracy: 0.2848\n",
            "Epoch 57/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 3.3133 - accuracy: 0.2885\n",
            "Epoch 58/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 3.1805 - accuracy: 0.3152\n",
            "Epoch 59/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 3.1867 - accuracy: 0.3098\n",
            "Epoch 60/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 3.0260 - accuracy: 0.3421\n",
            "Epoch 61/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 2.9311 - accuracy: 0.3680\n",
            "Epoch 62/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 2.8139 - accuracy: 0.3925\n",
            "Epoch 63/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 2.7212 - accuracy: 0.4036\n",
            "Epoch 64/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 2.6267 - accuracy: 0.4321\n",
            "Epoch 65/300\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 2.5696 - accuracy: 0.4368\n",
            "Epoch 66/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 2.4834 - accuracy: 0.4571\n",
            "Epoch 67/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 2.3965 - accuracy: 0.4828\n",
            "Epoch 68/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 2.3160 - accuracy: 0.5047\n",
            "Epoch 69/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 2.2528 - accuracy: 0.5156\n",
            "Epoch 70/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 2.1973 - accuracy: 0.5328\n",
            "Epoch 71/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 2.1417 - accuracy: 0.5431\n",
            "Epoch 72/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 2.0687 - accuracy: 0.5573\n",
            "Epoch 73/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 2.0321 - accuracy: 0.5660\n",
            "Epoch 74/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 1.9662 - accuracy: 0.5865\n",
            "Epoch 75/300\n",
            "34/34 [==============================] - 4s 133ms/step - loss: 1.9000 - accuracy: 0.6016\n",
            "Epoch 76/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 1.8251 - accuracy: 0.6058\n",
            "Epoch 77/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 1.7725 - accuracy: 0.6273\n",
            "Epoch 78/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 1.7219 - accuracy: 0.6473\n",
            "Epoch 79/300\n",
            "34/34 [==============================] - 3s 103ms/step - loss: 1.6665 - accuracy: 0.6551\n",
            "Epoch 80/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 1.6530 - accuracy: 0.6622\n",
            "Epoch 81/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 1.5752 - accuracy: 0.6806\n",
            "Epoch 82/300\n",
            "34/34 [==============================] - 3s 91ms/step - loss: 1.4992 - accuracy: 0.7049\n",
            "Epoch 83/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 1.4377 - accuracy: 0.7178\n",
            "Epoch 84/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 1.4203 - accuracy: 0.7188\n",
            "Epoch 85/300\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 1.3865 - accuracy: 0.7214\n",
            "Epoch 86/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 1.3371 - accuracy: 0.7400\n",
            "Epoch 87/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 1.2957 - accuracy: 0.7445\n",
            "Epoch 88/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 1.2463 - accuracy: 0.7621\n",
            "Epoch 89/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 1.2013 - accuracy: 0.7669\n",
            "Epoch 90/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 1.1660 - accuracy: 0.7857\n",
            "Epoch 91/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 1.1459 - accuracy: 0.7819\n",
            "Epoch 92/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 1.1227 - accuracy: 0.7881\n",
            "Epoch 93/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 1.1125 - accuracy: 0.7881\n",
            "Epoch 94/300\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 1.0848 - accuracy: 0.7926\n",
            "Epoch 95/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 1.0632 - accuracy: 0.7980\n",
            "Epoch 96/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 1.0148 - accuracy: 0.8083\n",
            "Epoch 97/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.9676 - accuracy: 0.8220\n",
            "Epoch 98/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.9338 - accuracy: 0.8281\n",
            "Epoch 99/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 1.5490 - accuracy: 0.6608\n",
            "Epoch 100/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 1.4996 - accuracy: 0.6473\n",
            "Epoch 101/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 1.1706 - accuracy: 0.7487\n",
            "Epoch 102/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 1.0703 - accuracy: 0.7756\n",
            "Epoch 103/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.9519 - accuracy: 0.8126\n",
            "Epoch 104/300\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.8653 - accuracy: 0.8399\n",
            "Epoch 105/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.8275 - accuracy: 0.8541\n",
            "Epoch 106/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.8599 - accuracy: 0.8357\n",
            "Epoch 107/300\n",
            "34/34 [==============================] - 3s 92ms/step - loss: 0.8009 - accuracy: 0.8557\n",
            "Epoch 108/300\n",
            "34/34 [==============================] - 3s 92ms/step - loss: 0.7542 - accuracy: 0.8682\n",
            "Epoch 109/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.7229 - accuracy: 0.8765\n",
            "Epoch 110/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.6881 - accuracy: 0.8821\n",
            "Epoch 111/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.6595 - accuracy: 0.8876\n",
            "Epoch 112/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.6516 - accuracy: 0.8939\n",
            "Epoch 113/300\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.6291 - accuracy: 0.8932\n",
            "Epoch 114/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.5900 - accuracy: 0.9097\n",
            "Epoch 115/300\n",
            "34/34 [==============================] - 3s 91ms/step - loss: 0.6180 - accuracy: 0.8927\n",
            "Epoch 116/300\n",
            "34/34 [==============================] - 3s 103ms/step - loss: 0.5864 - accuracy: 0.9031\n",
            "Epoch 117/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.5592 - accuracy: 0.9097\n",
            "Epoch 118/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.6001 - accuracy: 0.8944\n",
            "Epoch 119/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.5798 - accuracy: 0.9041\n",
            "Epoch 120/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.5610 - accuracy: 0.9062\n",
            "Epoch 121/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.5276 - accuracy: 0.9182\n",
            "Epoch 122/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.5064 - accuracy: 0.9194\n",
            "Epoch 123/300\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.4975 - accuracy: 0.9220\n",
            "Epoch 124/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.4653 - accuracy: 0.9281\n",
            "Epoch 125/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.4404 - accuracy: 0.9328\n",
            "Epoch 126/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.4468 - accuracy: 0.9288\n",
            "Epoch 127/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.4470 - accuracy: 0.9283\n",
            "Epoch 128/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.4420 - accuracy: 0.9314\n",
            "Epoch 129/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.4365 - accuracy: 0.9305\n",
            "Epoch 130/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.4077 - accuracy: 0.9387\n",
            "Epoch 131/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.4026 - accuracy: 0.9349\n",
            "Epoch 132/300\n",
            "34/34 [==============================] - 5s 136ms/step - loss: 0.4232 - accuracy: 0.9345\n",
            "Epoch 133/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.4080 - accuracy: 0.9354\n",
            "Epoch 134/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.4064 - accuracy: 0.9333\n",
            "Epoch 135/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.3870 - accuracy: 0.9397\n",
            "Epoch 136/300\n",
            "34/34 [==============================] - 4s 105ms/step - loss: 0.3710 - accuracy: 0.9413\n",
            "Epoch 137/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.3707 - accuracy: 0.9413\n",
            "Epoch 138/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.3542 - accuracy: 0.9467\n",
            "Epoch 139/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.3510 - accuracy: 0.9444\n",
            "Epoch 140/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.3222 - accuracy: 0.9540\n",
            "Epoch 141/300\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.2959 - accuracy: 0.9595\n",
            "Epoch 142/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.2889 - accuracy: 0.9604\n",
            "Epoch 143/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.2851 - accuracy: 0.9592\n",
            "Epoch 144/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.2780 - accuracy: 0.9623\n",
            "Epoch 145/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.2820 - accuracy: 0.9592\n",
            "Epoch 146/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.3092 - accuracy: 0.9543\n",
            "Epoch 147/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.2859 - accuracy: 0.9559\n",
            "Epoch 148/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.3220 - accuracy: 0.9470\n",
            "Epoch 149/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.3297 - accuracy: 0.9432\n",
            "Epoch 150/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.2955 - accuracy: 0.9521\n",
            "Epoch 151/300\n",
            "34/34 [==============================] - 5s 140ms/step - loss: 0.2883 - accuracy: 0.9521\n",
            "Epoch 152/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.2956 - accuracy: 0.9543\n",
            "Epoch 153/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.3076 - accuracy: 0.9503\n",
            "Epoch 154/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.3741 - accuracy: 0.9302\n",
            "Epoch 155/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.4052 - accuracy: 0.9173\n",
            "Epoch 156/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.4038 - accuracy: 0.9147\n",
            "Epoch 157/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.3595 - accuracy: 0.9302\n",
            "Epoch 158/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.2878 - accuracy: 0.9526\n",
            "Epoch 159/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.2877 - accuracy: 0.9538\n",
            "Epoch 160/300\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.2932 - accuracy: 0.9486\n",
            "Epoch 161/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.2692 - accuracy: 0.9545\n",
            "Epoch 162/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.2334 - accuracy: 0.9628\n",
            "Epoch 163/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.2012 - accuracy: 0.9710\n",
            "Epoch 164/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.1831 - accuracy: 0.9757\n",
            "Epoch 165/300\n",
            "34/34 [==============================] - 3s 103ms/step - loss: 0.1695 - accuracy: 0.9771\n",
            "Epoch 166/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.1637 - accuracy: 0.9821\n",
            "Epoch 167/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.1551 - accuracy: 0.9800\n",
            "Epoch 168/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.1445 - accuracy: 0.9807\n",
            "Epoch 169/300\n",
            "34/34 [==============================] - 4s 126ms/step - loss: 0.1523 - accuracy: 0.9826\n",
            "Epoch 170/300\n",
            "34/34 [==============================] - 4s 101ms/step - loss: 0.1468 - accuracy: 0.9830\n",
            "Epoch 171/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.1298 - accuracy: 0.9856\n",
            "Epoch 172/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.1270 - accuracy: 0.9854\n",
            "Epoch 173/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.1230 - accuracy: 0.9868\n",
            "Epoch 174/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.1157 - accuracy: 0.9877\n",
            "Epoch 175/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.1086 - accuracy: 0.9884\n",
            "Epoch 176/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.1160 - accuracy: 0.9861\n",
            "Epoch 177/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.1099 - accuracy: 0.9882\n",
            "Epoch 178/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.1090 - accuracy: 0.9889\n",
            "Epoch 179/300\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.1210 - accuracy: 0.9844\n",
            "Epoch 180/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.1188 - accuracy: 0.9866\n",
            "Epoch 181/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.1163 - accuracy: 0.9859\n",
            "Epoch 182/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.1152 - accuracy: 0.9859\n",
            "Epoch 183/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.1158 - accuracy: 0.9877\n",
            "Epoch 184/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.1223 - accuracy: 0.9859\n",
            "Epoch 185/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.1311 - accuracy: 0.9859\n",
            "Epoch 186/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.1430 - accuracy: 0.9795\n",
            "Epoch 187/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.1482 - accuracy: 0.9788\n",
            "Epoch 188/300\n",
            "34/34 [==============================] - 5s 140ms/step - loss: 0.1820 - accuracy: 0.9691\n",
            "Epoch 189/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.2860 - accuracy: 0.9359\n",
            "Epoch 190/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.4043 - accuracy: 0.9043\n",
            "Epoch 191/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.4498 - accuracy: 0.8883\n",
            "Epoch 192/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.5465 - accuracy: 0.8548\n",
            "Epoch 193/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.4300 - accuracy: 0.8986\n",
            "Epoch 194/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.3723 - accuracy: 0.9142\n",
            "Epoch 195/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.2991 - accuracy: 0.9309\n",
            "Epoch 196/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.2933 - accuracy: 0.9349\n",
            "Epoch 197/300\n",
            "34/34 [==============================] - 4s 130ms/step - loss: 0.2481 - accuracy: 0.9458\n",
            "Epoch 198/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.1787 - accuracy: 0.9670\n",
            "Epoch 199/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.1482 - accuracy: 0.9767\n",
            "Epoch 200/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.1233 - accuracy: 0.9802\n",
            "Epoch 201/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.1027 - accuracy: 0.9859\n",
            "Epoch 202/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0976 - accuracy: 0.9884\n",
            "Epoch 203/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0830 - accuracy: 0.9903\n",
            "Epoch 204/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0769 - accuracy: 0.9910\n",
            "Epoch 205/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0759 - accuracy: 0.9906\n",
            "Epoch 206/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0842 - accuracy: 0.9892\n",
            "Epoch 207/300\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.0787 - accuracy: 0.9922\n",
            "Epoch 208/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0724 - accuracy: 0.9915\n",
            "Epoch 209/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0667 - accuracy: 0.9946\n",
            "Epoch 210/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.0658 - accuracy: 0.9927\n",
            "Epoch 211/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0699 - accuracy: 0.9929\n",
            "Epoch 212/300\n",
            "34/34 [==============================] - 3s 92ms/step - loss: 0.0665 - accuracy: 0.9920\n",
            "Epoch 213/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0611 - accuracy: 0.9941\n",
            "Epoch 214/300\n",
            "34/34 [==============================] - 4s 103ms/step - loss: 0.0587 - accuracy: 0.9946\n",
            "Epoch 215/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.0563 - accuracy: 0.9955\n",
            "Epoch 216/300\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.0548 - accuracy: 0.9950\n",
            "Epoch 217/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0531 - accuracy: 0.9965\n",
            "Epoch 218/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0522 - accuracy: 0.9939\n",
            "Epoch 219/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0538 - accuracy: 0.9943\n",
            "Epoch 220/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.0516 - accuracy: 0.9943\n",
            "Epoch 221/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.0577 - accuracy: 0.9943\n",
            "Epoch 222/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0584 - accuracy: 0.9943\n",
            "Epoch 223/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0515 - accuracy: 0.9962\n",
            "Epoch 224/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0526 - accuracy: 0.9934\n",
            "Epoch 225/300\n",
            "34/34 [==============================] - 4s 111ms/step - loss: 0.0468 - accuracy: 0.9955\n",
            "Epoch 226/300\n",
            "34/34 [==============================] - 4s 115ms/step - loss: 0.0517 - accuracy: 0.9958\n",
            "Epoch 227/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0490 - accuracy: 0.9953\n",
            "Epoch 228/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.0530 - accuracy: 0.9953\n",
            "Epoch 229/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.0496 - accuracy: 0.9946\n",
            "Epoch 230/300\n",
            "34/34 [==============================] - 3s 92ms/step - loss: 0.0521 - accuracy: 0.9950\n",
            "Epoch 231/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.0504 - accuracy: 0.9955\n",
            "Epoch 232/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0551 - accuracy: 0.9943\n",
            "Epoch 233/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.0523 - accuracy: 0.9948\n",
            "Epoch 234/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0834 - accuracy: 0.9863\n",
            "Epoch 235/300\n",
            "34/34 [==============================] - 5s 135ms/step - loss: 0.4851 - accuracy: 0.8699\n",
            "Epoch 236/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.8850 - accuracy: 0.7685\n",
            "Epoch 237/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 1.0126 - accuracy: 0.7275\n",
            "Epoch 238/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.8609 - accuracy: 0.7687\n",
            "Epoch 239/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.6694 - accuracy: 0.8208\n",
            "Epoch 240/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.5697 - accuracy: 0.8444\n",
            "Epoch 241/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.3438 - accuracy: 0.9104\n",
            "Epoch 242/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.2310 - accuracy: 0.9474\n",
            "Epoch 243/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.1379 - accuracy: 0.9731\n",
            "Epoch 244/300\n",
            "34/34 [==============================] - 3s 103ms/step - loss: 0.1135 - accuracy: 0.9781\n",
            "Epoch 245/300\n",
            "34/34 [==============================] - 4s 126ms/step - loss: 0.0790 - accuracy: 0.9887\n",
            "Epoch 246/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0679 - accuracy: 0.9913\n",
            "Epoch 247/300\n",
            "34/34 [==============================] - 3s 92ms/step - loss: 0.0620 - accuracy: 0.9925\n",
            "Epoch 248/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.0562 - accuracy: 0.9932\n",
            "Epoch 249/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0548 - accuracy: 0.9936\n",
            "Epoch 250/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0541 - accuracy: 0.9920\n",
            "Epoch 251/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0465 - accuracy: 0.9962\n",
            "Epoch 252/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0564 - accuracy: 0.9936\n",
            "Epoch 253/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0544 - accuracy: 0.9941\n",
            "Epoch 254/300\n",
            "34/34 [==============================] - 5s 134ms/step - loss: 0.0453 - accuracy: 0.9962\n",
            "Epoch 255/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.0435 - accuracy: 0.9953\n",
            "Epoch 256/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0403 - accuracy: 0.9967\n",
            "Epoch 257/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0363 - accuracy: 0.9962\n",
            "Epoch 258/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0382 - accuracy: 0.9958\n",
            "Epoch 259/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.0366 - accuracy: 0.9962\n",
            "Epoch 260/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0343 - accuracy: 0.9967\n",
            "Epoch 261/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.0379 - accuracy: 0.9950\n",
            "Epoch 262/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0314 - accuracy: 0.9969\n",
            "Epoch 263/300\n",
            "34/34 [==============================] - 4s 133ms/step - loss: 0.0324 - accuracy: 0.9965\n",
            "Epoch 264/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.0285 - accuracy: 0.9981\n",
            "Epoch 265/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0313 - accuracy: 0.9972\n",
            "Epoch 266/300\n",
            "34/34 [==============================] - 3s 93ms/step - loss: 0.0282 - accuracy: 0.9979\n",
            "Epoch 267/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0296 - accuracy: 0.9979\n",
            "Epoch 268/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.0291 - accuracy: 0.9979\n",
            "Epoch 269/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0361 - accuracy: 0.9965\n",
            "Epoch 270/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0313 - accuracy: 0.9974\n",
            "Epoch 271/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0353 - accuracy: 0.9953\n",
            "Epoch 272/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0327 - accuracy: 0.9979\n",
            "Epoch 273/300\n",
            "34/34 [==============================] - 4s 133ms/step - loss: 0.0321 - accuracy: 0.9969\n",
            "Epoch 274/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.0304 - accuracy: 0.9958\n",
            "Epoch 275/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.0264 - accuracy: 0.9976\n",
            "Epoch 276/300\n",
            "34/34 [==============================] - 4s 104ms/step - loss: 0.0270 - accuracy: 0.9981\n",
            "Epoch 277/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0281 - accuracy: 0.9972\n",
            "Epoch 278/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.0273 - accuracy: 0.9974\n",
            "Epoch 279/300\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.0288 - accuracy: 0.9972\n",
            "Epoch 280/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.0273 - accuracy: 0.9981\n",
            "Epoch 281/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0263 - accuracy: 0.9972\n",
            "Epoch 282/300\n",
            "34/34 [==============================] - 5s 133ms/step - loss: 0.0261 - accuracy: 0.9981\n",
            "Epoch 283/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.0240 - accuracy: 0.9979\n",
            "Epoch 284/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.0242 - accuracy: 0.9972\n",
            "Epoch 285/300\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.0212 - accuracy: 0.9998\n",
            "Epoch 286/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.0230 - accuracy: 0.9983\n",
            "Epoch 287/300\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.0256 - accuracy: 0.9976\n",
            "Epoch 288/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0273 - accuracy: 0.9981\n",
            "Epoch 289/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.0252 - accuracy: 0.9974\n",
            "Epoch 290/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0228 - accuracy: 0.9983\n",
            "Epoch 291/300\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.0307 - accuracy: 0.9979\n",
            "Epoch 292/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0315 - accuracy: 0.9962\n",
            "Epoch 293/300\n",
            "34/34 [==============================] - 3s 102ms/step - loss: 0.0340 - accuracy: 0.9955\n",
            "Epoch 294/300\n",
            "34/34 [==============================] - 3s 94ms/step - loss: 0.0507 - accuracy: 0.9920\n",
            "Epoch 295/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0617 - accuracy: 0.9889\n",
            "Epoch 296/300\n",
            "34/34 [==============================] - 3s 101ms/step - loss: 0.2900 - accuracy: 0.9201\n",
            "Epoch 297/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.8522 - accuracy: 0.7687\n",
            "Epoch 298/300\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.8511 - accuracy: 0.7652\n",
            "Epoch 299/300\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.8870 - accuracy: 0.7539\n",
            "Epoch 300/300\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.6147 - accuracy: 0.8220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c931aaf70>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model_T1.fit(X, y, batch_size=128, epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4Geg4JVgagxv"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# function to generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        yhat=model.predict(encoded,verbose=0) \n",
        "        yhat=np.argmax(yhat,axis=1)\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "        in_text += ' ' + out_word\n",
        "        result.append(out_word)\n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncPQun-LfoTh",
        "outputId": "b4dad837-f73f-4986-ffeb-d1cd97e567ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the community or if they are able to speak they turn falsewitnesses and informers small catalogue of crimes truly even if the perpetrators are yes i said but small and great are relative terms and no crimes which are committed by them approach those of the tyrant whom this class growing\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from random import randint\n",
        "# select the random line of the text data\n",
        "random_text = sequences[randint(0,len(sequences))]\n",
        "print(random_text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgVjIhVIfLGe",
        "outputId": "e0bf03a2-aa06-47c0-b990-f961ee6098d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if the moral book nature that are always will a defence will all in so tales stranger tyrant that are know will have that are do will a very will have as say we we his spirit of be claims as is his opposite who the good certainly we temperance\n"
          ]
        }
      ],
      "source": [
        "generated = generate_seq(model_T1, tokenizer, seq_length, random_text, 50) \n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hzdrvMW0PwyS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBazgwLOPxDe"
      },
      "source": [
        "##Trial_2 using LSTM, Embedding, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3xGJSTOyPxDf"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qB2ZwUKMPxDf"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model_T2 = Sequential()\n",
        "model_T2.add(Embedding(vocab_size,50,input_length=seq_length))\n",
        "model_T2.add(LSTM(200, return_sequences=True))\n",
        "model_T2.add(LSTM(200))\n",
        "model_T2.add(Dropout(0.2))\n",
        "model_T2.add(Dense(vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJByNKjiPxDg",
        "outputId": "b7e2f9f3-4320-431c-ae3c-a1ed261902b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 50)            524500    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50, 200)           200800    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 200)               320800    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10490)             2108490   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,154,590\n",
            "Trainable params: 3,154,590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_T2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "D3OomH-SPxDg"
      },
      "outputs": [],
      "source": [
        "model_T2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVYBrR1XPxDg",
        "outputId": "5b5f896e-9114-4c5a-96e5-8ce716e423d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 7s 22ms/step - loss: 7.7911 - accuracy: 0.0615\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 6.2027 - accuracy: 0.0752\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 6.0209 - accuracy: 0.0754\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9496 - accuracy: 0.0754\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9254 - accuracy: 0.0721\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9239 - accuracy: 0.0745\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9159 - accuracy: 0.0747\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9078 - accuracy: 0.0733\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9089 - accuracy: 0.0750\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9100 - accuracy: 0.0752\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9082 - accuracy: 0.0757\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9017 - accuracy: 0.0745\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9056 - accuracy: 0.0731\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8976 - accuracy: 0.0764\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8879 - accuracy: 0.0759\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8964 - accuracy: 0.0766\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8961 - accuracy: 0.0745\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8855 - accuracy: 0.0698\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8796 - accuracy: 0.0759\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8810 - accuracy: 0.0759\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8780 - accuracy: 0.0710\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8754 - accuracy: 0.0757\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8662 - accuracy: 0.0759\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.8246 - accuracy: 0.0759\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.7041 - accuracy: 0.0783\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.6116 - accuracy: 0.0853\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.5229 - accuracy: 0.0976\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.4483 - accuracy: 0.1016\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 5.3882 - accuracy: 0.1080\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.3290 - accuracy: 0.1103\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.2754 - accuracy: 0.1099\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.2226 - accuracy: 0.1165\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.1610 - accuracy: 0.1176\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.1035 - accuracy: 0.1188\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.0491 - accuracy: 0.1219\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.0046 - accuracy: 0.1235\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 4.9611 - accuracy: 0.1254\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 4.9162 - accuracy: 0.1273\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 4.8517 - accuracy: 0.1327\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 4.7919 - accuracy: 0.1381\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 4.7300 - accuracy: 0.1384\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 4.6819 - accuracy: 0.1459\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 4.6202 - accuracy: 0.1532\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 4.5634 - accuracy: 0.1608\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 4.5081 - accuracy: 0.1631\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.4609 - accuracy: 0.1667\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.4040 - accuracy: 0.1744\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.3443 - accuracy: 0.1808\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 4.3038 - accuracy: 0.1853\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.2565 - accuracy: 0.1954\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.2145 - accuracy: 0.2008\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.1593 - accuracy: 0.2032\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.1133 - accuracy: 0.2089\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 4.0606 - accuracy: 0.2138\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 4.0148 - accuracy: 0.2223\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 3.9974 - accuracy: 0.2209\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 3.9169 - accuracy: 0.2308\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.8709 - accuracy: 0.2289\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.8295 - accuracy: 0.2412\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.7938 - accuracy: 0.2390\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.7827 - accuracy: 0.2466\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.7148 - accuracy: 0.2534\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.6551 - accuracy: 0.2626\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.6385 - accuracy: 0.2603\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.5863 - accuracy: 0.2720\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.5636 - accuracy: 0.2746\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.5246 - accuracy: 0.2763\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.4853 - accuracy: 0.2831\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.4494 - accuracy: 0.2867\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.4186 - accuracy: 0.2890\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.3792 - accuracy: 0.2989\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.3513 - accuracy: 0.2947\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.3075 - accuracy: 0.3107\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.2719 - accuracy: 0.3114\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.2454 - accuracy: 0.3119\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 3.2160 - accuracy: 0.3093\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.1858 - accuracy: 0.3234\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.1409 - accuracy: 0.3293\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.1126 - accuracy: 0.3340\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.1097 - accuracy: 0.3378\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.0881 - accuracy: 0.3289\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.0395 - accuracy: 0.3512\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.0028 - accuracy: 0.3491\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.9778 - accuracy: 0.3593\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.9548 - accuracy: 0.3607\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.9158 - accuracy: 0.3607\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.8966 - accuracy: 0.3692\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.8677 - accuracy: 0.3689\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.8408 - accuracy: 0.3758\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 2.8142 - accuracy: 0.3930\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 2.7909 - accuracy: 0.3800\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 2.7622 - accuracy: 0.3918\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 2.7470 - accuracy: 0.3958\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.7119 - accuracy: 0.4036\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.6835 - accuracy: 0.4071\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.6647 - accuracy: 0.4066\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.6625 - accuracy: 0.4059\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.6588 - accuracy: 0.4083\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.6152 - accuracy: 0.4132\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.5851 - accuracy: 0.4231\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.5434 - accuracy: 0.4286\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.4995 - accuracy: 0.4477\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.4805 - accuracy: 0.4465\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.4531 - accuracy: 0.4524\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.4471 - accuracy: 0.4550\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.4109 - accuracy: 0.4616\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.3864 - accuracy: 0.4653\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.3882 - accuracy: 0.4637\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.3761 - accuracy: 0.4632\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3670 - accuracy: 0.4620\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3460 - accuracy: 0.4625\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3099 - accuracy: 0.4689\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.2719 - accuracy: 0.4974\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.2513 - accuracy: 0.5005\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2330 - accuracy: 0.4960\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1980 - accuracy: 0.5097\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.2012 - accuracy: 0.5073\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1587 - accuracy: 0.5203\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1370 - accuracy: 0.5189\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1247 - accuracy: 0.5196\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.1081 - accuracy: 0.5210\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1775 - accuracy: 0.5066\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1178 - accuracy: 0.5160\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1221 - accuracy: 0.5090\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.1006 - accuracy: 0.5236\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.0555 - accuracy: 0.5335\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 2.0150 - accuracy: 0.5471\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.9933 - accuracy: 0.5540\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.9634 - accuracy: 0.5658\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.9309 - accuracy: 0.5698\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.8994 - accuracy: 0.5769\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.8991 - accuracy: 0.5799\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.8663 - accuracy: 0.5858\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.8426 - accuracy: 0.5934\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.8324 - accuracy: 0.5962\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.8175 - accuracy: 0.5978\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.8037 - accuracy: 0.6091\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.7880 - accuracy: 0.5976\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.7803 - accuracy: 0.6011\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.7716 - accuracy: 0.6155\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 1.7552 - accuracy: 0.6103\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 1.7395 - accuracy: 0.6157\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 1.7215 - accuracy: 0.6209\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.7570 - accuracy: 0.6040\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.7268 - accuracy: 0.6132\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.7146 - accuracy: 0.6207\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.6971 - accuracy: 0.6304\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.6790 - accuracy: 0.6146\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.6330 - accuracy: 0.6429\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.6114 - accuracy: 0.6459\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.6102 - accuracy: 0.6431\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.5988 - accuracy: 0.6447\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.5755 - accuracy: 0.6572\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.5458 - accuracy: 0.6690\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.5379 - accuracy: 0.6594\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.5300 - accuracy: 0.6624\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.5141 - accuracy: 0.6737\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4952 - accuracy: 0.6690\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4932 - accuracy: 0.6747\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4736 - accuracy: 0.6766\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4551 - accuracy: 0.6855\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4456 - accuracy: 0.6853\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4678 - accuracy: 0.6742\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4662 - accuracy: 0.6810\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4373 - accuracy: 0.6832\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4641 - accuracy: 0.6728\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4635 - accuracy: 0.6763\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.4238 - accuracy: 0.6810\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.3931 - accuracy: 0.6992\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.3603 - accuracy: 0.7091\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.3411 - accuracy: 0.7143\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.3109 - accuracy: 0.7223\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.3002 - accuracy: 0.7166\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.2859 - accuracy: 0.7240\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.2713 - accuracy: 0.7291\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.2707 - accuracy: 0.7223\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.2507 - accuracy: 0.7280\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.2395 - accuracy: 0.7430\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.2396 - accuracy: 0.7343\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.2143 - accuracy: 0.7419\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.2260 - accuracy: 0.7355\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.2164 - accuracy: 0.7402\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.2092 - accuracy: 0.7395\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.1844 - accuracy: 0.7494\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.1957 - accuracy: 0.7447\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.1973 - accuracy: 0.7416\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.1830 - accuracy: 0.7456\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.1649 - accuracy: 0.7513\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 1.1455 - accuracy: 0.7574\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 1.1378 - accuracy: 0.7565\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 1s 22ms/step - loss: 1.1244 - accuracy: 0.7560\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.1369 - accuracy: 0.7572\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.1264 - accuracy: 0.7593\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.1194 - accuracy: 0.7636\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.0975 - accuracy: 0.7624\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.0896 - accuracy: 0.7673\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.1285 - accuracy: 0.7494\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.1440 - accuracy: 0.7456\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.1101 - accuracy: 0.7537\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.0683 - accuracy: 0.7723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c2c271070>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model_T2.fit(X, y, batch_size=128, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tAb4iQxePxDg"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# function to generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        yhat=model.predict(encoded,verbose=0) \n",
        "        yhat=np.argmax(yhat,axis=1)\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "        in_text += ' ' + out_word\n",
        "        result.append(out_word)\n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTIrKC0CPxDh",
        "outputId": "cef10850-3b40-4b09-ca4b-4e290e12e2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "that the word which you have uttered is one at which numerous persons and very respectable persons too in a figure pulling off their coats all in a moment and seizing any weapon that comes to hand will run at you might and main before you know where you are intending\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from random import randint\n",
        "# select the random line of the text data\n",
        "random_text = sequences[randint(0,len(sequences))]\n",
        "print(random_text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B0FkkmYPxDh",
        "outputId": "fe3658e5-f193-4c86-bfd3-01c95d72a347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "us things with are be up why then that i said yes will if in the state of them as this having will if is another an abroad between in a musician noticed aware that are all no sleepy public gradually cruel perfect tale of which the other important such\n"
          ]
        }
      ],
      "source": [
        "generated = generate_seq(model_T2, tokenizer, seq_length, random_text, 50) \n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75C5rSbJOYta"
      },
      "source": [
        "##Trial_3 using  GRU, Embedding, Dense, SpatialDropout1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CxWmd0VOPS3G"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense,SpatialDropout1D, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qaY1772yRt0l"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model_T3 = Sequential()\n",
        "model_T3.add(Embedding(vocab_size,50,input_length=seq_length))\n",
        "model_T3.add(SpatialDropout1D(0.2))\n",
        "model_T3.add(GRU(200, return_sequences=True))\n",
        "model_T3.add(GRU(200))\n",
        "model_T3.add(Dense(vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPfRT-8fRt0m",
        "outputId": "c2834168-24a4-46bb-c2ed-3e7860700ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 50, 50)            524500    \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 50, 50)           0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 50, 200)           151200    \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 200)               241200    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10490)             2108490   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,025,390\n",
            "Trainable params: 3,025,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_T3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4AJMaB7FRt0n"
      },
      "outputs": [],
      "source": [
        "model_T3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj1F0awHRt0n",
        "outputId": "ecb6b7ae-9ae6-4365-a0a2-deea98b6abab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 3s 20ms/step - loss: 7.8255 - accuracy: 0.0702\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 6.1739 - accuracy: 0.0759\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 1s 16ms/step - loss: 5.9820 - accuracy: 0.0759\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9311 - accuracy: 0.0759\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9259 - accuracy: 0.0740\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9199 - accuracy: 0.0759\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9174 - accuracy: 0.0759\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9283 - accuracy: 0.0759\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9203 - accuracy: 0.0759\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9160 - accuracy: 0.0759\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9236 - accuracy: 0.0759\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9184 - accuracy: 0.0759\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9156 - accuracy: 0.0759\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9208 - accuracy: 0.0759\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9196 - accuracy: 0.0710\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9207 - accuracy: 0.0646\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9153 - accuracy: 0.0754\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9182 - accuracy: 0.0712\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9209 - accuracy: 0.0681\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9172 - accuracy: 0.0759\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 5.9167 - accuracy: 0.0759\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 1s 21ms/step - loss: 5.9185 - accuracy: 0.0759\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 5.9093 - accuracy: 0.0759\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9231 - accuracy: 0.0759\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9181 - accuracy: 0.0759\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9139 - accuracy: 0.0759\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9153 - accuracy: 0.0759\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9142 - accuracy: 0.0759\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9142 - accuracy: 0.0759\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9132 - accuracy: 0.0759\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9178 - accuracy: 0.0759\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9097 - accuracy: 0.0759\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9180 - accuracy: 0.0759\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9178 - accuracy: 0.0710\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9120 - accuracy: 0.0759\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9140 - accuracy: 0.0759\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9167 - accuracy: 0.0705\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9146 - accuracy: 0.0712\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9208 - accuracy: 0.0726\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9071 - accuracy: 0.0759\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9170 - accuracy: 0.0717\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9144 - accuracy: 0.0660\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9167 - accuracy: 0.0759\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9135 - accuracy: 0.0759\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9181 - accuracy: 0.0759\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9147 - accuracy: 0.0759\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9067 - accuracy: 0.0759\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9132 - accuracy: 0.0712\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9147 - accuracy: 0.0759\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9124 - accuracy: 0.0759\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9132 - accuracy: 0.0700\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9205 - accuracy: 0.0724\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9202 - accuracy: 0.0759\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9167 - accuracy: 0.0719\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9128 - accuracy: 0.0759\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9194 - accuracy: 0.0759\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9132 - accuracy: 0.0759\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9145 - accuracy: 0.0759\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9143 - accuracy: 0.0759\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9162 - accuracy: 0.0759\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9141 - accuracy: 0.0759\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9131 - accuracy: 0.0759\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9147 - accuracy: 0.0702\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9160 - accuracy: 0.0691\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9108 - accuracy: 0.0743\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9155 - accuracy: 0.0759\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9197 - accuracy: 0.0759\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9159 - accuracy: 0.0759\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9079 - accuracy: 0.0759\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9229 - accuracy: 0.0759\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9142 - accuracy: 0.0736\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9142 - accuracy: 0.0759\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9132 - accuracy: 0.0698\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 5.9119 - accuracy: 0.0707\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 5.9219 - accuracy: 0.0665\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 5.9224 - accuracy: 0.0759\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9135 - accuracy: 0.0759\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9135 - accuracy: 0.0759\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9188 - accuracy: 0.0759\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9133 - accuracy: 0.0721\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9118 - accuracy: 0.0702\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9201 - accuracy: 0.0700\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9124 - accuracy: 0.0759\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9108 - accuracy: 0.0700\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9163 - accuracy: 0.0658\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9171 - accuracy: 0.0754\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9066 - accuracy: 0.0759\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9112 - accuracy: 0.0759\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9249 - accuracy: 0.0618\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9180 - accuracy: 0.0693\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9138 - accuracy: 0.0759\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9142 - accuracy: 0.0759\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9152 - accuracy: 0.0667\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9103 - accuracy: 0.0700\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9159 - accuracy: 0.0759\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9193 - accuracy: 0.0710\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9129 - accuracy: 0.0710\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9161 - accuracy: 0.0660\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9109 - accuracy: 0.0759\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9169 - accuracy: 0.0759\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9105 - accuracy: 0.0702\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9125 - accuracy: 0.0677\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9057 - accuracy: 0.0759\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9119 - accuracy: 0.0759\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9133 - accuracy: 0.0759\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9121 - accuracy: 0.0759\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9090 - accuracy: 0.0733\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9084 - accuracy: 0.0750\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9176 - accuracy: 0.0705\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9148 - accuracy: 0.0759\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9178 - accuracy: 0.0698\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9151 - accuracy: 0.0759\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9096 - accuracy: 0.0759\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9120 - accuracy: 0.0759\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9165 - accuracy: 0.0759\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9094 - accuracy: 0.0698\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9092 - accuracy: 0.0759\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9082 - accuracy: 0.0759\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9141 - accuracy: 0.0693\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9083 - accuracy: 0.0759\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9133 - accuracy: 0.0759\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9135 - accuracy: 0.0695\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9088 - accuracy: 0.0759\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9112 - accuracy: 0.0759\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9070 - accuracy: 0.0759\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9139 - accuracy: 0.0759\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9099 - accuracy: 0.0759\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9158 - accuracy: 0.0714\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 5.9127 - accuracy: 0.0759\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 5.9142 - accuracy: 0.0759\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 5.9141 - accuracy: 0.0705\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9143 - accuracy: 0.0759\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9142 - accuracy: 0.0759\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9184 - accuracy: 0.0759\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9133 - accuracy: 0.0759\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9185 - accuracy: 0.0759\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.9162 - accuracy: 0.0759\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9102 - accuracy: 0.0759\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9077 - accuracy: 0.0759\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9116 - accuracy: 0.0759\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9122 - accuracy: 0.0759\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9106 - accuracy: 0.0759\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9159 - accuracy: 0.0719\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9064 - accuracy: 0.0759\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.9175 - accuracy: 0.0757\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.8469 - accuracy: 0.0759\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.8375 - accuracy: 0.0759\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.7450 - accuracy: 0.0759\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.6904 - accuracy: 0.0759\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.6060 - accuracy: 0.0764\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 5.5079 - accuracy: 0.0771\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.3988 - accuracy: 0.0794\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.3150 - accuracy: 0.0893\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.1544 - accuracy: 0.0974\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 5.0022 - accuracy: 0.1087\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 4.8317 - accuracy: 0.1209\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 4.6653 - accuracy: 0.1327\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 4.5042 - accuracy: 0.1485\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 4.3499 - accuracy: 0.1565\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 4.1913 - accuracy: 0.1763\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 4.0296 - accuracy: 0.1900\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.8662 - accuracy: 0.2091\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.7109 - accuracy: 0.2240\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.5561 - accuracy: 0.2487\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 3.4102 - accuracy: 0.2834\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.2712 - accuracy: 0.3053\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.1319 - accuracy: 0.3232\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 3.0142 - accuracy: 0.3687\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.8647 - accuracy: 0.4085\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.6919 - accuracy: 0.4439\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.5782 - accuracy: 0.4724\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.4615 - accuracy: 0.5108\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.3323 - accuracy: 0.5384\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.2024 - accuracy: 0.5875\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 2.0682 - accuracy: 0.6103\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 1.9564 - accuracy: 0.6455\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 1.8513 - accuracy: 0.6787\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 1.7489 - accuracy: 0.7039\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 1.6260 - accuracy: 0.7254\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 1.5448 - accuracy: 0.7577\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.4454 - accuracy: 0.7706\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.3460 - accuracy: 0.7845\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 1s 20ms/step - loss: 1.2615 - accuracy: 0.8062\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 1.1818 - accuracy: 0.8256\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 1.1157 - accuracy: 0.8305\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 1.0416 - accuracy: 0.8487\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.9713 - accuracy: 0.8642\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.9200 - accuracy: 0.8694\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.8640 - accuracy: 0.8864\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.8026 - accuracy: 0.8918\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.7539 - accuracy: 0.9031\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.7283 - accuracy: 0.9010\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.6724 - accuracy: 0.9109\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.6256 - accuracy: 0.9173\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.5986 - accuracy: 0.9227\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 1s 17ms/step - loss: 0.5624 - accuracy: 0.9316\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.5256 - accuracy: 0.9356\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.5031 - accuracy: 0.9340\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4713 - accuracy: 0.9432\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.4531 - accuracy: 0.9406\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6cfb3233a0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "model_T3.fit(X, y, batch_size=128, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "atIAu12rRt0o"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# function to generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        yhat=model.predict(encoded,verbose=0) \n",
        "        yhat=np.argmax(yhat,axis=1)\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "        in_text += ' ' + out_word\n",
        "        result.append(out_word)\n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElbiigxCRt0p",
        "outputId": "3eaf6ae5-ad13-4b6d-98a2-ef6d6ebbffa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "as the community of women and children the community of property and the constitution of the state the population is divided into two of husbandmen and the other of warriors from this latter is taken a third class of counsellors and rulers of the state but socrates has not determined whether\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from random import randint\n",
        "# select the random line of the text data\n",
        "random_text = sequences[randint(0,len(sequences))]\n",
        "print(random_text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orA_DNvxRt0p",
        "outputId": "fd6ed86a-8a7b-4b2d-c85e-33d6cf6407c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sounds out which which men i said no things are are there which has there are say made yet first we have have have but there have be not under things into all no not not if who no or the best but they the good of the good of\n"
          ]
        }
      ],
      "source": [
        "generated = generate_seq(model_T3, tokenizer, seq_length, random_text, 50) \n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3Bu-5z4EObnE"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np0W889kWnqd"
      },
      "source": [
        "##Trial_4 using  Bidirectional RNN (LSTM) Embedding, Dense, SpatialDropout1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "SBaHpWUjWnqe"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense,SpatialDropout1D, Bidirectional, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "PfBxhEdaWnqe"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model_T4 = Sequential()\n",
        "model_T4.add(Embedding(vocab_size,50,input_length=seq_length))\n",
        "model_T4.add(SpatialDropout1D(0.2))\n",
        "model_T4.add(Bidirectional(LSTM(200, return_sequences=True)))\n",
        "model_T4.add(Bidirectional(LSTM(200, return_sequences=False)))\n",
        "model_T4.add(Dense(vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXxLPtSlWnqe",
        "outputId": "6e766169-6151-4fe4-bd33-72941e58102a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 50, 50)            524500    \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 50, 50)           0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 400)          401600    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 400)              961600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10490)             4206490   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,094,190\n",
            "Trainable params: 6,094,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_T4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "pE3kiOLUWnqf"
      },
      "outputs": [],
      "source": [
        "model_T4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWlTuYqQWnqf",
        "outputId": "9d56c291-5b9c-4880-d3c6-56d9f1649ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 6s 39ms/step - loss: 7.6832 - accuracy: 0.0644\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 1s 35ms/step - loss: 6.1131 - accuracy: 0.0759\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 1s 35ms/step - loss: 5.9356 - accuracy: 0.0759\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 1s 35ms/step - loss: 5.8983 - accuracy: 0.0759\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 5.8726 - accuracy: 0.0759\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 5.7599 - accuracy: 0.0759\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 5.6319 - accuracy: 0.0827\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 5.5165 - accuracy: 0.0898\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 5.4016 - accuracy: 0.1035\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 5.2771 - accuracy: 0.1108\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 5.1880 - accuracy: 0.1205\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 5.0976 - accuracy: 0.1165\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 4.9837 - accuracy: 0.1308\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 4.8635 - accuracy: 0.1372\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 4.7777 - accuracy: 0.1370\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 4.6851 - accuracy: 0.1433\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 4.5948 - accuracy: 0.1483\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 4.5356 - accuracy: 0.1513\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 4.5210 - accuracy: 0.1575\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 4.3360 - accuracy: 0.1662\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 4.2760 - accuracy: 0.1669\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 4.2103 - accuracy: 0.1794\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 4.1196 - accuracy: 0.1834\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 4.0184 - accuracy: 0.1886\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 3.9329 - accuracy: 0.1980\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 3.8409 - accuracy: 0.2107\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 3.7563 - accuracy: 0.2117\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 3.6757 - accuracy: 0.2214\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 3.6034 - accuracy: 0.2244\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 3.5090 - accuracy: 0.2447\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 3.4601 - accuracy: 0.2489\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 3.3689 - accuracy: 0.2546\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 3.2781 - accuracy: 0.2709\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 3.1736 - accuracy: 0.2876\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 3.0827 - accuracy: 0.3039\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 2.9975 - accuracy: 0.3248\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.9147 - accuracy: 0.3385\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.8199 - accuracy: 0.3614\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.7362 - accuracy: 0.3753\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.6652 - accuracy: 0.3920\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.5814 - accuracy: 0.4165\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.5152 - accuracy: 0.4382\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.4353 - accuracy: 0.4498\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.3832 - accuracy: 0.4696\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.3021 - accuracy: 0.4932\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.2338 - accuracy: 0.5151\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.1611 - accuracy: 0.5229\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.1069 - accuracy: 0.5358\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 2.0717 - accuracy: 0.5587\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 2.0297 - accuracy: 0.5622\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.9256 - accuracy: 0.5898\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 2.0871 - accuracy: 0.5375\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.9255 - accuracy: 0.5728\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 1.8122 - accuracy: 0.6157\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 1.7545 - accuracy: 0.6273\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.6434 - accuracy: 0.6608\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.5956 - accuracy: 0.6711\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.5346 - accuracy: 0.6855\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.5048 - accuracy: 0.6964\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.4831 - accuracy: 0.6919\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 1.3863 - accuracy: 0.7240\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 1.3260 - accuracy: 0.7346\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.2837 - accuracy: 0.7532\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.2416 - accuracy: 0.7647\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.2174 - accuracy: 0.7593\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.2252 - accuracy: 0.7567\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.3323 - accuracy: 0.7235\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 1.1683 - accuracy: 0.7636\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 1.1127 - accuracy: 0.7801\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 1.0454 - accuracy: 0.7982\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.9897 - accuracy: 0.8164\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.9514 - accuracy: 0.8187\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.9217 - accuracy: 0.8239\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.8972 - accuracy: 0.8317\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.8541 - accuracy: 0.8395\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.8468 - accuracy: 0.8418\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.9260 - accuracy: 0.8194\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.8463 - accuracy: 0.8388\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.8057 - accuracy: 0.8510\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.7597 - accuracy: 0.8564\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.7136 - accuracy: 0.8744\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.7412 - accuracy: 0.8623\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.6800 - accuracy: 0.8769\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.6517 - accuracy: 0.8852\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.6100 - accuracy: 0.8979\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.6323 - accuracy: 0.8871\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.5732 - accuracy: 0.9038\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.5640 - accuracy: 0.9017\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.5400 - accuracy: 0.9154\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.5356 - accuracy: 0.9095\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.5021 - accuracy: 0.9208\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.4782 - accuracy: 0.9283\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.4683 - accuracy: 0.9288\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.4565 - accuracy: 0.9323\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.4396 - accuracy: 0.9418\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.4317 - accuracy: 0.9349\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.4104 - accuracy: 0.9422\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.3946 - accuracy: 0.9463\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.3847 - accuracy: 0.9458\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.3649 - accuracy: 0.9536\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.3528 - accuracy: 0.9540\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.3260 - accuracy: 0.9606\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.3264 - accuracy: 0.9611\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.3084 - accuracy: 0.9613\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2955 - accuracy: 0.9665\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2744 - accuracy: 0.9734\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2712 - accuracy: 0.9705\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2682 - accuracy: 0.9701\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2472 - accuracy: 0.9767\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 1s 42ms/step - loss: 0.2316 - accuracy: 0.9760\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 1s 40ms/step - loss: 0.2354 - accuracy: 0.9762\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.2519 - accuracy: 0.9705\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.2417 - accuracy: 0.9719\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.2570 - accuracy: 0.9684\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.2312 - accuracy: 0.9743\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.2046 - accuracy: 0.9793\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.1963 - accuracy: 0.9807\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1857 - accuracy: 0.9835\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.1741 - accuracy: 0.9861\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.1757 - accuracy: 0.9856\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1593 - accuracy: 0.9894\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1511 - accuracy: 0.9901\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1477 - accuracy: 0.9901\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1415 - accuracy: 0.9925\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.1397 - accuracy: 0.9908\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1359 - accuracy: 0.9901\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.1494 - accuracy: 0.9863\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2225 - accuracy: 0.9722\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2027 - accuracy: 0.9727\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.1591 - accuracy: 0.9849\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1496 - accuracy: 0.9856\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.2073 - accuracy: 0.9717\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.2058 - accuracy: 0.9701\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.1381 - accuracy: 0.9868\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1753 - accuracy: 0.9769\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1479 - accuracy: 0.9854\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1236 - accuracy: 0.9903\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.1135 - accuracy: 0.9920\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 0.1047 - accuracy: 0.9941\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0985 - accuracy: 0.9943\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0932 - accuracy: 0.9950\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0845 - accuracy: 0.9974\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0827 - accuracy: 0.9950\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0834 - accuracy: 0.9965\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0759 - accuracy: 0.9950\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1531 - accuracy: 0.9760\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1641 - accuracy: 0.9760\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1598 - accuracy: 0.9776\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1305 - accuracy: 0.9868\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1672 - accuracy: 0.9755\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 0.2330 - accuracy: 0.9547\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1361 - accuracy: 0.9842\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.1090 - accuracy: 0.9882\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0906 - accuracy: 0.9941\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0779 - accuracy: 0.9950\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0749 - accuracy: 0.9950\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0702 - accuracy: 0.9953\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0632 - accuracy: 0.9958\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0618 - accuracy: 0.9958\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0663 - accuracy: 0.9936\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0550 - accuracy: 0.9974\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0464 - accuracy: 0.9995\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.0453 - accuracy: 0.9983\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.0448 - accuracy: 0.9974\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0427 - accuracy: 0.9979\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 0.0444 - accuracy: 0.9976\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 0.0447 - accuracy: 0.9981\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 0.0427 - accuracy: 0.9983\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 1s 38ms/step - loss: 0.0392 - accuracy: 0.9995\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0383 - accuracy: 0.9988\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0346 - accuracy: 0.9986\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0343 - accuracy: 0.9988\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0723 - accuracy: 0.9903\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0643 - accuracy: 0.9925\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0554 - accuracy: 0.9958\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0465 - accuracy: 0.9976\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0444 - accuracy: 0.9974\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0428 - accuracy: 0.9969\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0409 - accuracy: 0.9981\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0352 - accuracy: 0.9983\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0390 - accuracy: 0.9967\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0417 - accuracy: 0.9965\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0329 - accuracy: 0.9983\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0360 - accuracy: 0.9976\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0324 - accuracy: 0.9991\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0281 - accuracy: 0.9986\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0306 - accuracy: 0.9981\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 1s 39ms/step - loss: 0.0268 - accuracy: 0.9988\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 1s 40ms/step - loss: 0.0298 - accuracy: 0.9988\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0298 - accuracy: 0.9988\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0365 - accuracy: 0.9967\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0327 - accuracy: 0.9976\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0338 - accuracy: 0.9972\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0452 - accuracy: 0.9948\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0450 - accuracy: 0.9943\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0333 - accuracy: 0.9981\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0254 - accuracy: 0.9983\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.0269 - accuracy: 0.9981\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 1s 36ms/step - loss: 0.0211 - accuracy: 0.9995\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 1s 37ms/step - loss: 0.0300 - accuracy: 0.9979\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c24360370>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model_T4.fit(X, y, batch_size=128, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "bnuA8zs5Wnqg"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# function to generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        yhat=model.predict(encoded,verbose=0) \n",
        "        yhat=np.argmax(yhat,axis=1)\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "        in_text += ' ' + out_word\n",
        "        result.append(out_word)\n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "LNJMbL0-Wnqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4e8bf2-eaee-40e7-b5d4-0ff3beaf21c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to what do you refer we were saying if i am not mistaken that he who wanted to see them in their perfect beauty must take a longer and more circuitous way at the end of which they would appear but that we could add on a popular exposition of them\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from random import randint\n",
        "# select the random line of the text data\n",
        "random_text = sequences[randint(0,len(sequences))]\n",
        "print(random_text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "dLoQGRrZWnqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e585743-07f7-457a-e2cd-18bc2f5cd4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from be required from them to men to be yet perfectly ferocity and the whole able and the whole and their state but a one a human important which man he will will him must him that the judge not not have what are a more nature gymnastics true which\n"
          ]
        }
      ],
      "source": [
        "generated = generate_seq(model_T4, tokenizer, seq_length, random_text, 50) \n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vjH1BKUoWdw3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHKTDSeOX4lY"
      },
      "source": [
        "##Trial_5 using  Bidirectional RNN (GRU) Embedding, Dense, SpatialDropout1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ZA1WSpj3X4lZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense,SpatialDropout1D, Bidirectional, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "179efgxhX4la",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33c9015-51ea-4108-ecc0-1833e7cebc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model_T5 = Sequential()\n",
        "model_T5.add(Embedding(vocab_size,50,input_length=seq_length))\n",
        "model_T5.add(SpatialDropout1D(0.2))\n",
        "model_T5.add(Bidirectional(GRU(100, return_sequences=True,activation=\"tanh\", recurrent_activation=\"sigmoid\",dropout=0.1,recurrent_dropout=0.1)))\n",
        "model_T5.add(Bidirectional(GRU(100, return_sequences=False,activation=\"tanh\", recurrent_activation=\"sigmoid\",dropout=0.1,recurrent_dropout=0.1)))\n",
        "model_T5.add(Dense(vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "jUlbNG8ZcuoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191a0cf4-0e3f-4255-feed-f2f219f26e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.rnn.bidirectional.Bidirectional at 0x7f6bc34a95b0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "Bidirectional(GRU(100, return_sequences=True,activation=\"tanh\", recurrent_activation=\"sigmoid\",dropout=0.1,recurrent_dropout=0.1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCvQu8s5X4la",
        "outputId": "52dfb396-60f6-48ea-eecd-2389678f3082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 50, 50)            524500    \n",
            "                                                                 \n",
            " spatial_dropout1d_2 (Spatia  (None, 50, 50)           0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 50, 200)          91200     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 200)              181200    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10490)             2108490   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,905,390\n",
            "Trainable params: 2,905,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_T5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9p8Sa1NtX4lb"
      },
      "outputs": [],
      "source": [
        "model_T5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFPo7TCRX4lc",
        "outputId": "409cd40b-fba3-48c7-e607-3b38ae3579dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 34s 763ms/step - loss: 8.0211 - accuracy: 0.0733\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 26s 752ms/step - loss: 6.1087 - accuracy: 0.0747\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 25s 741ms/step - loss: 5.9228 - accuracy: 0.0717\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 26s 751ms/step - loss: 5.8747 - accuracy: 0.0759\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 25s 725ms/step - loss: 5.8523 - accuracy: 0.0759\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 26s 760ms/step - loss: 5.8049 - accuracy: 0.0759\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 26s 764ms/step - loss: 5.7001 - accuracy: 0.0769\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 26s 778ms/step - loss: 5.5926 - accuracy: 0.0759\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 26s 768ms/step - loss: 5.5242 - accuracy: 0.0702\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 25s 734ms/step - loss: 5.4674 - accuracy: 0.0757\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 26s 759ms/step - loss: 5.4103 - accuracy: 0.0764\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 25s 750ms/step - loss: 5.3546 - accuracy: 0.0870\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 26s 761ms/step - loss: 5.2941 - accuracy: 0.0905\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 26s 767ms/step - loss: 5.2095 - accuracy: 0.0938\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 5.1477 - accuracy: 0.1004\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 25s 745ms/step - loss: 5.0844 - accuracy: 0.1056\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 26s 754ms/step - loss: 5.0457 - accuracy: 0.1054\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 26s 763ms/step - loss: 5.0111 - accuracy: 0.1042\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 25s 730ms/step - loss: 4.9500 - accuracy: 0.1117\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 25s 739ms/step - loss: 4.8883 - accuracy: 0.1124\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 25s 746ms/step - loss: 4.8182 - accuracy: 0.1157\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 24s 712ms/step - loss: 4.7680 - accuracy: 0.1228\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 25s 725ms/step - loss: 4.7144 - accuracy: 0.1254\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 25s 722ms/step - loss: 4.6785 - accuracy: 0.1254\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 24s 721ms/step - loss: 4.6672 - accuracy: 0.1176\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 26s 751ms/step - loss: 4.5827 - accuracy: 0.1207\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 4.5076 - accuracy: 0.1299\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 24s 720ms/step - loss: 4.4544 - accuracy: 0.1360\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 25s 723ms/step - loss: 4.3972 - accuracy: 0.1384\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 25s 736ms/step - loss: 4.3289 - accuracy: 0.1412\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 24s 717ms/step - loss: 4.2773 - accuracy: 0.1485\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 25s 728ms/step - loss: 4.2053 - accuracy: 0.1556\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 24s 707ms/step - loss: 4.1474 - accuracy: 0.1582\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 24s 719ms/step - loss: 4.1006 - accuracy: 0.1678\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 24s 720ms/step - loss: 4.1348 - accuracy: 0.1641\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 24s 718ms/step - loss: 4.0940 - accuracy: 0.1690\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 26s 762ms/step - loss: 4.0068 - accuracy: 0.1700\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 24s 718ms/step - loss: 3.9211 - accuracy: 0.1749\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 25s 723ms/step - loss: 3.8508 - accuracy: 0.1815\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 3.7975 - accuracy: 0.1931\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 25s 723ms/step - loss: 3.7252 - accuracy: 0.1942\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 26s 765ms/step - loss: 3.6600 - accuracy: 0.2070\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 25s 730ms/step - loss: 3.6038 - accuracy: 0.2178\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 24s 721ms/step - loss: 4.5200 - accuracy: 0.1737\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 24s 712ms/step - loss: 4.8353 - accuracy: 0.1377\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 24s 703ms/step - loss: 4.2732 - accuracy: 0.1565\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 26s 754ms/step - loss: 3.9771 - accuracy: 0.1832\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 24s 704ms/step - loss: 3.8129 - accuracy: 0.1942\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 24s 706ms/step - loss: 3.6619 - accuracy: 0.2150\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 24s 722ms/step - loss: 3.5244 - accuracy: 0.2251\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 3.3913 - accuracy: 0.2581\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 24s 707ms/step - loss: 3.2984 - accuracy: 0.2737\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 25s 746ms/step - loss: 3.2154 - accuracy: 0.2777\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 24s 720ms/step - loss: 3.0756 - accuracy: 0.3095\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 25s 729ms/step - loss: 2.9693 - accuracy: 0.3274\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 24s 719ms/step - loss: 2.8632 - accuracy: 0.3494\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 24s 719ms/step - loss: 2.7816 - accuracy: 0.3656\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 25s 744ms/step - loss: 2.6846 - accuracy: 0.3965\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 24s 713ms/step - loss: 2.6023 - accuracy: 0.4201\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 24s 715ms/step - loss: 2.5206 - accuracy: 0.4387\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 24s 716ms/step - loss: 2.4213 - accuracy: 0.4562\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 24s 701ms/step - loss: 2.3463 - accuracy: 0.4882\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 25s 734ms/step - loss: 2.2669 - accuracy: 0.4981\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 24s 711ms/step - loss: 2.1835 - accuracy: 0.5224\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 2.1230 - accuracy: 0.5306\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 24s 715ms/step - loss: 2.0567 - accuracy: 0.5580\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 24s 696ms/step - loss: 1.9998 - accuracy: 0.5622\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 26s 751ms/step - loss: 1.9390 - accuracy: 0.5787\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 24s 714ms/step - loss: 1.8904 - accuracy: 0.5837\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 25s 737ms/step - loss: 1.8121 - accuracy: 0.6054\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 24s 716ms/step - loss: 1.7362 - accuracy: 0.6278\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 24s 697ms/step - loss: 1.6891 - accuracy: 0.6363\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 24s 700ms/step - loss: 1.6281 - accuracy: 0.6490\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 25s 747ms/step - loss: 1.5802 - accuracy: 0.6558\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 24s 716ms/step - loss: 1.5378 - accuracy: 0.6657\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 24s 714ms/step - loss: 1.5168 - accuracy: 0.6697\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 24s 714ms/step - loss: 1.4348 - accuracy: 0.6924\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 24s 707ms/step - loss: 1.3997 - accuracy: 0.7020\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 25s 746ms/step - loss: 1.3738 - accuracy: 0.6983\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 25s 727ms/step - loss: 1.3348 - accuracy: 0.7122\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 24s 697ms/step - loss: 1.2812 - accuracy: 0.7376\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 25s 733ms/step - loss: 1.2411 - accuracy: 0.7317\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 24s 721ms/step - loss: 1.2083 - accuracy: 0.7386\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 25s 743ms/step - loss: 1.1727 - accuracy: 0.7508\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 1.1296 - accuracy: 0.7572\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 24s 700ms/step - loss: 1.0893 - accuracy: 0.7775\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 25s 721ms/step - loss: 1.0597 - accuracy: 0.7763\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 23s 688ms/step - loss: 1.0498 - accuracy: 0.7831\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 25s 739ms/step - loss: 1.0035 - accuracy: 0.7883\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 24s 701ms/step - loss: 0.9795 - accuracy: 0.7954\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 24s 721ms/step - loss: 0.9549 - accuracy: 0.7977\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 24s 697ms/step - loss: 0.9315 - accuracy: 0.8050\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 24s 704ms/step - loss: 0.9163 - accuracy: 0.7994\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 24s 718ms/step - loss: 0.8667 - accuracy: 0.8230\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 25s 725ms/step - loss: 0.8559 - accuracy: 0.8185\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 24s 698ms/step - loss: 0.8260 - accuracy: 0.8322\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 24s 701ms/step - loss: 0.8119 - accuracy: 0.8331\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 24s 719ms/step - loss: 0.7933 - accuracy: 0.8380\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 24s 696ms/step - loss: 0.7570 - accuracy: 0.8484\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 25s 745ms/step - loss: 0.7455 - accuracy: 0.8465\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 24s 704ms/step - loss: 0.7144 - accuracy: 0.8512\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 24s 708ms/step - loss: 0.6864 - accuracy: 0.8600\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 24s 702ms/step - loss: 0.6837 - accuracy: 0.8576\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 24s 719ms/step - loss: 0.6724 - accuracy: 0.8604\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 24s 706ms/step - loss: 0.6552 - accuracy: 0.8673\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 25s 748ms/step - loss: 0.6390 - accuracy: 0.8696\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 24s 697ms/step - loss: 0.6246 - accuracy: 0.8701\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 0.5942 - accuracy: 0.8843\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 24s 717ms/step - loss: 0.5774 - accuracy: 0.8802\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 24s 691ms/step - loss: 0.5543 - accuracy: 0.8871\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 25s 751ms/step - loss: 0.5590 - accuracy: 0.8906\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 25s 724ms/step - loss: 0.5377 - accuracy: 0.8946\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 0.5187 - accuracy: 0.9003\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 24s 716ms/step - loss: 0.5142 - accuracy: 0.8972\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 24s 699ms/step - loss: 0.5001 - accuracy: 0.9081\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 25s 738ms/step - loss: 0.4826 - accuracy: 0.9029\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 0.4743 - accuracy: 0.9135\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 24s 699ms/step - loss: 0.4589 - accuracy: 0.9083\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 24s 703ms/step - loss: 0.4496 - accuracy: 0.9128\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 24s 714ms/step - loss: 0.4319 - accuracy: 0.9163\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 0.4207 - accuracy: 0.9215\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 26s 750ms/step - loss: 0.3936 - accuracy: 0.9262\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 24s 709ms/step - loss: 0.3898 - accuracy: 0.9269\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 25s 738ms/step - loss: 0.3885 - accuracy: 0.9293\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 24s 722ms/step - loss: 0.3781 - accuracy: 0.9316\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 24s 713ms/step - loss: 0.3722 - accuracy: 0.9316\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 25s 745ms/step - loss: 0.3802 - accuracy: 0.9286\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 24s 693ms/step - loss: 0.3641 - accuracy: 0.9328\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 24s 701ms/step - loss: 0.3465 - accuracy: 0.9347\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 0.3436 - accuracy: 0.9382\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 24s 713ms/step - loss: 0.3217 - accuracy: 0.9467\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 24s 716ms/step - loss: 0.3130 - accuracy: 0.9406\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 25s 729ms/step - loss: 0.3068 - accuracy: 0.9422\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 24s 709ms/step - loss: 0.2989 - accuracy: 0.9488\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 23s 687ms/step - loss: 0.2913 - accuracy: 0.9488\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 25s 719ms/step - loss: 0.3101 - accuracy: 0.9479\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 24s 702ms/step - loss: 0.3131 - accuracy: 0.9444\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 25s 740ms/step - loss: 0.2694 - accuracy: 0.9543\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 24s 697ms/step - loss: 0.2586 - accuracy: 0.9590\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 24s 707ms/step - loss: 0.2750 - accuracy: 0.9538\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 0.2583 - accuracy: 0.9595\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 24s 719ms/step - loss: 0.2506 - accuracy: 0.9595\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 25s 736ms/step - loss: 0.2436 - accuracy: 0.9620\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 23s 691ms/step - loss: 0.2425 - accuracy: 0.9566\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 24s 699ms/step - loss: 0.2267 - accuracy: 0.9653\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 23s 690ms/step - loss: 0.2234 - accuracy: 0.9656\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 23s 686ms/step - loss: 0.2234 - accuracy: 0.9644\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 23s 692ms/step - loss: 0.2078 - accuracy: 0.9694\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 25s 735ms/step - loss: 0.2141 - accuracy: 0.9653\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 24s 716ms/step - loss: 0.1918 - accuracy: 0.9736\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 24s 699ms/step - loss: 0.1949 - accuracy: 0.9679\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 0.1895 - accuracy: 0.9731\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 24s 698ms/step - loss: 0.2080 - accuracy: 0.9628\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 25s 748ms/step - loss: 0.1901 - accuracy: 0.9717\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 24s 700ms/step - loss: 0.1768 - accuracy: 0.9771\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 24s 716ms/step - loss: 0.1713 - accuracy: 0.9762\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 24s 698ms/step - loss: 0.1718 - accuracy: 0.9727\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 24s 713ms/step - loss: 0.1617 - accuracy: 0.9741\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 24s 700ms/step - loss: 0.1602 - accuracy: 0.9802\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 25s 734ms/step - loss: 0.1539 - accuracy: 0.9788\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 24s 708ms/step - loss: 0.1626 - accuracy: 0.9748\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 24s 702ms/step - loss: 0.1680 - accuracy: 0.9743\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 0.1484 - accuracy: 0.9823\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 0.1443 - accuracy: 0.9816\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 25s 728ms/step - loss: 0.1406 - accuracy: 0.9807\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 24s 702ms/step - loss: 0.1334 - accuracy: 0.9842\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 24s 706ms/step - loss: 0.1431 - accuracy: 0.9797\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 24s 710ms/step - loss: 0.1332 - accuracy: 0.9816\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 24s 706ms/step - loss: 0.1390 - accuracy: 0.9795\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 25s 743ms/step - loss: 0.1232 - accuracy: 0.9837\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 24s 697ms/step - loss: 0.1195 - accuracy: 0.9861\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 24s 713ms/step - loss: 0.1190 - accuracy: 0.9856\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 24s 696ms/step - loss: 0.1213 - accuracy: 0.9830\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 24s 711ms/step - loss: 0.1277 - accuracy: 0.9826\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 24s 713ms/step - loss: 0.1197 - accuracy: 0.9842\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 25s 738ms/step - loss: 0.1021 - accuracy: 0.9896\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 24s 701ms/step - loss: 0.1036 - accuracy: 0.9889\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 24s 700ms/step - loss: 0.1012 - accuracy: 0.9882\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 24s 692ms/step - loss: 0.1085 - accuracy: 0.9844\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 0.1003 - accuracy: 0.9906\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 24s 718ms/step - loss: 0.1070 - accuracy: 0.9887\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 24s 694ms/step - loss: 0.1108 - accuracy: 0.9823\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 24s 700ms/step - loss: 0.1037 - accuracy: 0.9877\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 24s 698ms/step - loss: 0.1003 - accuracy: 0.9854\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 23s 689ms/step - loss: 0.0946 - accuracy: 0.9892\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 24s 705ms/step - loss: 0.1015 - accuracy: 0.9870\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 25s 740ms/step - loss: 0.0905 - accuracy: 0.9899\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 24s 702ms/step - loss: 0.0861 - accuracy: 0.9915\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 24s 709ms/step - loss: 0.0821 - accuracy: 0.9892\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 24s 702ms/step - loss: 0.0862 - accuracy: 0.9896\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 24s 702ms/step - loss: 0.1117 - accuracy: 0.9814\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 25s 730ms/step - loss: 0.0934 - accuracy: 0.9866\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 23s 692ms/step - loss: 0.0816 - accuracy: 0.9915\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 24s 691ms/step - loss: 0.0784 - accuracy: 0.9915\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 23s 682ms/step - loss: 0.0785 - accuracy: 0.9910\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 24s 696ms/step - loss: 0.0765 - accuracy: 0.9922\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 25s 749ms/step - loss: 0.0758 - accuracy: 0.9917\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 24s 703ms/step - loss: 0.0899 - accuracy: 0.9882\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 24s 700ms/step - loss: 0.0798 - accuracy: 0.9908\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 24s 706ms/step - loss: 0.0790 - accuracy: 0.9901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6bc32f9eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "model_T5.fit(X, y, batch_size=128, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "tOV2jpozX4lc"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# function to generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        yhat=model.predict(encoded,verbose=0) \n",
        "        yhat=np.argmax(yhat,axis=1)\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == yhat:\n",
        "                out_word = word\n",
        "                break\n",
        "        in_text += ' ' + out_word\n",
        "        result.append(out_word)\n",
        "    return ' '.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOSOHJFwX4ld",
        "outputId": "fbaefde4-45f3-4a5d-d01b-d5ab921e459b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes yes my good sir and there will be no better in which to look for a government why because of the liberty which reigns have a complete assortment of constitutions and he who has a mind to establish a state as we have been doing must go to a democracy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from random import randint\n",
        "# select the random line of the text data\n",
        "random_text = sequences[randint(0,len(sequences))]\n",
        "print(random_text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UgBmM2eX4le",
        "outputId": "a7e26174-2bc3-48d8-d4d9-ee60569f343b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i made but i objects whom your pauper world well admit how who if disposed feeling almost tyrant only who see how than modes exception i such then will a faculty yes may my wits going important important dream office proceed but justice may give not so last yes us\n"
          ]
        }
      ],
      "source": [
        "generated = generate_seq(model_T5, tokenizer, seq_length, random_text, 50) \n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "j3YlWor1X4le"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wNmL4B9I_40H",
        "tZy15UYxHtOk",
        "M6nvVuA6JNei",
        "8XYC6vyM97UE",
        "PtoatlKpSQP_",
        "zdMx1lAfUvuJ",
        "JBazgwLOPxDe",
        "75C5rSbJOYta",
        "np0W889kWnqd"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}